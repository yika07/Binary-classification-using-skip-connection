{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 38,
            "source": [
                "import torch\n",
                "from torch import nn\n",
                "import torch.nn.functional as F\n",
                "import numpy as np\n",
                "from sklearn.model_selection import train_test_split\n",
                "from torch.utils.data import TensorDataset, DataLoader\n",
                "from torch import FloatTensor\n",
                "from sklearn import datasets"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "source": [
                "iris = datasets.load_iris()\n",
                "x = iris.data\n",
                "y = iris.target"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "source": [
                "x_data = []\n",
                "y_data = []\n",
                "\n",
                "for i in range(len(x)):\n",
                "    if y[i] == 0 or y[i] == 1:\n",
                "        x_list = x[i].tolist()\n",
                "        x_data.append(x_list)\n",
                "        y_data.append(y[i])"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "source": [
                "x_train, x_test, y_train, y_test = train_test_split(x, y,\n",
                "                                                    test_size=10,\n",
                "                                                    random_state=42)\n",
                "\n",
                "train_idx = []\n",
                "test_idx = []\n",
                "\n",
                "for i in range(len(y_train)):\n",
                "    if y_train[i] == 2:\n",
                "        train_idx.append(i)\n",
                "\n",
                "for i in range(len(y_test)):\n",
                "    if y_test[i] == 2:\n",
                "        test_idx.append(i)\n",
                "\n",
                "x_train = np.delete(x_train, train_idx, axis=0)\n",
                "x_test = np.delete(x_test, test_idx, axis=0)\n",
                "\n",
                "y_train = np.delete(y_train, train_idx)\n",
                "y_test = np.delete(y_test, test_idx)\n",
                "\n",
                "x_train = np.array(x_train)\n",
                "y_train = np.array(y_train)\n",
                "x_test = np.array(x_test)\n",
                "y_test = np.array(y_test)\n",
                "\n",
                "Y_train = torch.as_tensor(y_train)\n",
                "Y_test = torch.as_tensor(y_test)\n",
                "\n",
                "train_set = TensorDataset(FloatTensor(x_train), Y_train)\n",
                "test_set = TensorDataset(FloatTensor(x_test), Y_test)\n",
                "\n",
                "train_set = DataLoader(train_set, batch_size=20)\n",
                "test_set = DataLoader(test_set, batch_size=1)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "source": [
                "class Circuit(nn.Module):\n",
                "    def __init__(self):\n",
                "        super().__init__()\n",
                "        self.fc1 = nn.Linear(4, 4)\n",
                "        self.fc2 = nn.Linear(4,4)\n",
                "        self.fc3 = nn.Linear(4,2)\n",
                "        \n",
                "    def forward(self, x):\n",
                "        x1 = F.relu(self.fc1(x))\n",
                "        x2 = F.tanh(self.fc2(x1))+x1\n",
                "        x3 = (self.fc3(x2))**2\n",
                "\n",
                "\n",
                "        return x3\n",
                "model = Circuit()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "source": [
                "criterion = nn.CrossEntropyLoss()\n",
                "\n",
                "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
                "# optimizer = torch.optim.Adam(model.parameters(), lr=0.1)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "source": [
                "n_epochs = 100\n",
                "LR = 0.01\n",
                "\n",
                "for epoch in range(n_epochs):\n",
                "    train_loss = 0.0\n",
                "    for data in train_set:\n",
                "\n",
                "        input = data[0]\n",
                "        # input = torch.tensor(input)\n",
                "        # input = input.type(torch.FloatTensor)\n",
                "        target = data[1]\n",
                "        # target = torch.tensor(target)\n",
                "        # target = target.type(torch.FloatTensor)\n",
                "        optimizer.zero_grad()\n",
                "        output = model(input)\n",
                "        loss = criterion(output,target)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        train_loss += loss.item()\n",
                "    train_loss = train_loss/len(x_train)\n",
                "    if epoch%2 == 0:\n",
                "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, train_loss))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Epoch: 1 \tTraining Loss: 0.044589\n",
                        "Epoch: 3 \tTraining Loss: 0.019300\n",
                        "Epoch: 5 \tTraining Loss: 0.000592\n",
                        "Epoch: 7 \tTraining Loss: 0.000016\n",
                        "Epoch: 9 \tTraining Loss: 0.000002\n",
                        "Epoch: 11 \tTraining Loss: 0.000001\n",
                        "Epoch: 13 \tTraining Loss: 0.000001\n",
                        "Epoch: 15 \tTraining Loss: 0.000001\n",
                        "Epoch: 17 \tTraining Loss: 0.000001\n",
                        "Epoch: 19 \tTraining Loss: 0.000001\n",
                        "Epoch: 21 \tTraining Loss: 0.000001\n",
                        "Epoch: 23 \tTraining Loss: 0.000001\n",
                        "Epoch: 25 \tTraining Loss: 0.000001\n",
                        "Epoch: 27 \tTraining Loss: 0.000001\n",
                        "Epoch: 29 \tTraining Loss: 0.000001\n",
                        "Epoch: 31 \tTraining Loss: 0.000001\n",
                        "Epoch: 33 \tTraining Loss: 0.000001\n",
                        "Epoch: 35 \tTraining Loss: 0.000001\n",
                        "Epoch: 37 \tTraining Loss: 0.000001\n",
                        "Epoch: 39 \tTraining Loss: 0.000001\n",
                        "Epoch: 41 \tTraining Loss: 0.000001\n",
                        "Epoch: 43 \tTraining Loss: 0.000001\n",
                        "Epoch: 45 \tTraining Loss: 0.000001\n",
                        "Epoch: 47 \tTraining Loss: 0.000001\n",
                        "Epoch: 49 \tTraining Loss: 0.000001\n",
                        "Epoch: 51 \tTraining Loss: 0.000001\n",
                        "Epoch: 53 \tTraining Loss: 0.000000\n",
                        "Epoch: 55 \tTraining Loss: 0.000000\n",
                        "Epoch: 57 \tTraining Loss: 0.000000\n",
                        "Epoch: 59 \tTraining Loss: 0.000000\n",
                        "Epoch: 61 \tTraining Loss: 0.000000\n",
                        "Epoch: 63 \tTraining Loss: 0.000000\n",
                        "Epoch: 65 \tTraining Loss: 0.000000\n",
                        "Epoch: 67 \tTraining Loss: 0.000000\n",
                        "Epoch: 69 \tTraining Loss: 0.000000\n",
                        "Epoch: 71 \tTraining Loss: 0.000000\n",
                        "Epoch: 73 \tTraining Loss: 0.000000\n",
                        "Epoch: 75 \tTraining Loss: 0.000000\n",
                        "Epoch: 77 \tTraining Loss: 0.000000\n",
                        "Epoch: 79 \tTraining Loss: 0.000000\n",
                        "Epoch: 81 \tTraining Loss: 0.000000\n",
                        "Epoch: 83 \tTraining Loss: 0.000000\n",
                        "Epoch: 85 \tTraining Loss: 0.000000\n",
                        "Epoch: 87 \tTraining Loss: 0.000000\n",
                        "Epoch: 89 \tTraining Loss: 0.000000\n",
                        "Epoch: 91 \tTraining Loss: 0.000000\n",
                        "Epoch: 93 \tTraining Loss: 0.000000\n",
                        "Epoch: 95 \tTraining Loss: 0.000000\n",
                        "Epoch: 97 \tTraining Loss: 0.000000\n",
                        "Epoch: 99 \tTraining Loss: 0.000000\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "/Users/aikyrasolomanana/opt/anaconda3/envs/pythonProject/lib/python3.9/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
                        "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "source": [
                "def test(network, data):\n",
                "    # tests the accuracy of the network on the dataset data and returns it (the accuracy)\n",
                "    correct_count = 0\n",
                "    all_count = 0\n",
                "\n",
                "    with torch.no_grad():\n",
                "        for x, y in data:\n",
                "            outputs = network(x)\n",
                "            _, pred = torch.max(outputs.data, 1)\n",
                "            all_count += y.size(0)\n",
                "            correct_count += (pred == y).sum().item()\n",
                "\n",
                "    return correct_count / all_count"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "source": [
                "print(test(model,train_set))\n",
                "print(test(model,test_set))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "1.0\n",
                        "1.0\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.5",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.5 64-bit ('pythonProject': conda)"
        },
        "interpreter": {
            "hash": "2554f967321230018be31673a68daafab85c8548764b989b26aa1b80b87ff581"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}